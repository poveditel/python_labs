from src.lib.text import normalize, count_freq, top_n, tokenize

print()

print("–ü—Ä–ò–≤–ï—Ç/n–ú–ò—Ä/t ‚Üí ", normalize("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"))
print("—ë–∂–∏–∫, –Å–ª–∫–∞ (yo2e=True) ‚Üí", normalize("—ë–∂–∏–∫, –Å–ª–∫–∞", yo2e=True))
print("Hello\r\nWorld  ‚Üí", normalize("Hello\r\nWorld"))
print("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ‚Üí ", normalize("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "))

print()
print()

print("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä ‚Üí ", tokenize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"))
print("hello,world!!! ‚Üí ", tokenize("hello,world!!!"))
print("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ ‚Üí ", tokenize("–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ"))
print("2007 –≥–æ–¥ ‚Üí ", tokenize("2007 –≥–æ–¥"))
print("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ ‚Üí ", tokenize("emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"))

print()
print()

print(
    'count_freq(["a","b","a","c","b","a","a","c","b","a","a","c","b","a"]) ‚Üí ',
    count_freq(["a", "b", "a", "c", "b", "a", "a", "c", "b", "a", "a", "c", "b", "a"]),
)
print()
print(
    "top_n(..., n=2) ‚Üí ",
    top_n(
        count_freq(
            ["a", "b", "a", "c", "b", "a", "a", "c", "b", "a", "a", "c", "b", "a"]
        )
    ),
)
print()
print(
    'top_n(..., n=4) ["bb","aa","bb","aa","cc", "bb","aa","cc", "bb","aa","cc"]‚Üí ',
    top_n(
        count_freq(["bb", "aa", "bb", "aa", "cc", "bb", "aa", "cc", "bb", "aa", "cc"]),
        n=4,
    ),
)

print()
print()
